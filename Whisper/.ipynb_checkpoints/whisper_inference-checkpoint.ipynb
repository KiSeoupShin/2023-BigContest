{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in c:\\users\\rltjq09\\anaconda3\\envs\\test\\lib\\site-packages (2.0.1)\n",
      "Collecting torchvision\n",
      "  Using cached https://download.pytorch.org/whl/cu118/torchvision-0.15.2%2Bcu118-cp38-cp38-win_amd64.whl (4.9 MB)\n",
      "Collecting torchaudio\n",
      "  Using cached https://download.pytorch.org/whl/cu118/torchaudio-2.0.2%2Bcu118-cp38-cp38-win_amd64.whl (2.5 MB)\n",
      "Requirement already satisfied: filelock in c:\\users\\rltjq09\\anaconda3\\envs\\test\\lib\\site-packages (from torch) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\rltjq09\\anaconda3\\envs\\test\\lib\\site-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\rltjq09\\anaconda3\\envs\\test\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\rltjq09\\anaconda3\\envs\\test\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\rltjq09\\anaconda3\\envs\\test\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\rltjq09\\anaconda3\\envs\\test\\lib\\site-packages (from torchvision) (1.24.4)\n",
      "Requirement already satisfied: requests in c:\\users\\rltjq09\\anaconda3\\envs\\test\\lib\\site-packages (from torchvision) (2.31.0)\n",
      "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision)\n",
      "  Using cached https://download.pytorch.org/whl/Pillow-9.3.0-cp38-cp38-win_amd64.whl (2.5 MB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\rltjq09\\anaconda3\\envs\\test\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rltjq09\\anaconda3\\envs\\test\\lib\\site-packages (from requests->torchvision) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rltjq09\\anaconda3\\envs\\test\\lib\\site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rltjq09\\anaconda3\\envs\\test\\lib\\site-packages (from requests->torchvision) (2.0.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rltjq09\\anaconda3\\envs\\test\\lib\\site-packages (from requests->torchvision) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\rltjq09\\anaconda3\\envs\\test\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Installing collected packages: pillow, torchvision, torchaudio\n",
      "Successfully installed pillow-9.3.0 torchaudio-2.0.2+cu118 torchvision-0.15.2+cu118\n"
     ]
    }
   ],
   "source": [
    "# Install packages\n",
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install git+https://github.com/openai/whisper.git \n",
    "!pip install pydub\n",
    "!pip install wave\n",
    "!pip install numpy\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wave\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import whisper\n",
    "import os\n",
    "\n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ../audio/ 폴더에 최초의 영상에서 추출한 음성을 저장\n",
    "# 해당 폴더에 존재하는 음성 파일들의 파일명을 모두 불러와 리스트 형태로 저장\n",
    "\n",
    "folder_path = '../Data/audio/'\n",
    "file_list = os.listdir(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whisper 모델은 m4a 형식이 아닌 wav 형식을 사용\n",
    "# 이에 맞춰 기존의 m4a 형식을 wav 형식으로 변환\n",
    "# 변환 후 ../wav_audio/ 폴더에 변환된 음성 파일들을 저장\n",
    "\n",
    "for file in file_list:\n",
    "    # m4a 파일 로드\n",
    "    audio = AudioSegment.from_file(\"../Data/audio/\" + file, format=\"m4a\")\n",
    "\n",
    "    # wav 파일로 저장\n",
    "    audio.export(\"../Data/wav_audio/\" + file.split('.')[0] + '.wav', format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변환된 wav 파일들을 ../wav_audio/ 폴더에서 불러옴\n",
    "# 해당 폴더에 존재하는 음성 파일들의 파일명을 모두 불러와 리스트 형태로 저장\n",
    "\n",
    "folder_path = '../Data/wav_audio/'\n",
    "file_list = os.listdir(folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Word vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 대한씨름협회 유튜브에 존재하는 '55가지 씨름 공식 기술 소개│씨름 기술 55수' 영상에 존재하는 씨름의 기술들을 사용하여 씨름 기술 단어 사전을 생성\n",
    "# 단어들을 technique이라는 변수에 리스트로 저장\n",
    "\n",
    "technique = '''\n",
    "앞무릎치기\n",
    "앞무릎짚기\n",
    "모둠앞무릎치기\n",
    "앞무릎뒤집기\n",
    "앞무릎짚고밀기\n",
    "뒷무릎치기\n",
    "옆무릎치기\n",
    "뒷무릎\n",
    "앞무릎\n",
    "옆무릎\n",
    "오른옆무릎치기\n",
    "콩꺾기\n",
    "오금당기기\n",
    "앞다리들기\n",
    "손짚이기\n",
    "호미걸이\n",
    "낚시걸이\n",
    "뒤축걸이\n",
    "뒷발목걸이\n",
    "앞다리차기\n",
    "무릎대어돌리기\n",
    "연장걸이\n",
    "빗장걸이\n",
    "밭다리걸기\n",
    "밭다리치기\n",
    "밭다리감아돌리기\n",
    "안다리걸기\n",
    "왼안다리걸기\n",
    "덧걸이\n",
    "덮걸이\n",
    "오금걸이\n",
    "안다리\n",
    "밭다리\n",
    "배지기\n",
    "왼배지기\n",
    "오른배지기\n",
    "엉덩배지기\n",
    "차돌리기\n",
    "어깨걸어치기\n",
    "업어던지기\n",
    "들배지기\n",
    "들베지기\n",
    "들어튕겨배지기\n",
    "들며차내어배지기\n",
    "들며튕겨배지기\n",
    "들어잡채기\n",
    "잡치기\n",
    "후려던지기\n",
    "들어찧기\n",
    "들안아놓기\n",
    "들어낚시걸이\n",
    "들어호미걸이\n",
    "뿌려치기\n",
    "밀어치기\n",
    "등채기\n",
    "등쳐감아돌리기\n",
    "애목잡치기\n",
    "정면뒤집기\n",
    "뒤집기\n",
    "측면뒤집기\n",
    "목감아뒤집기\n",
    "끌어치기\n",
    "꼭뒤집기\n",
    "앞으로누르기\n",
    "통안아넘기기\n",
    "허리꺾기\n",
    "땡기기\n",
    "'''\n",
    "tech_list = list(technique.split('\\n'))\n",
    "tech_list = tech_list[1:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whisper 모델을 불러옴\n",
    "# whisper 모델이 사용하는 checkpoint 중 가장 용량이 큰 'large' checkpoint를 불러와서 사용\n",
    "# model이라는 변수에 해당 모델을 저장\n",
    "\n",
    "model = whisper.load_model(\"large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tech_df라는 데이터프래임 생성\n",
    "# 해당 변수에는 파일명과 기술 사용 횟수가 저장될 예정\n",
    "\n",
    "tech_df = pd.DataFrame(columns=['title','tech_count'])\n",
    "\n",
    "# result_list라는 빈 리스트 생성\n",
    "# 해당 리스트에는 model이 STT를 수행한 결과인 Text를 리스트 형태로 저장\n",
    "\n",
    "result_list = []\n",
    "\n",
    "# decode_options라는 dictionary 생성\n",
    "# whisper는 다양한 언어를 지원하기 때문에 언어를 지정하지 않으면 한국어가 아닌 다른 나라의 언어로 예측할 위험이 있음\n",
    "# 이를 방지하기 위해 language를 한국어로 고정하는 변수를 생성\n",
    "\n",
    "decode_options = {'language' : 'ko'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, file_ in enumerate(file_list): # file_list에 저장된 wav 파일들을 하나씩 불러온다.\n",
    "    file = folder_path + file_ # file_list에는 파일명만 존재하기 때문에 파일을 정상적으로 불러오기 위해 파일 경로를 더해줌으로써 파일을 정상적으로 불러온다.\n",
    "    title = list(file.split(' '))[1] # 파일명은 '(Audio) 금강_16_1_1_0.wav'와 같은 형태로 구성되어 있기 때문에 띄어쓰기를 기준으로 분할 후 2번째 단어를 저장한다.\n",
    "    title = list(title.split('.'))[0] # 위에서 저장한 단어에서 .을 기준으로 다시 분할한 후 중요한 부분인 1번째 단어를 최종 title로 저장\n",
    "\n",
    "\n",
    "    # whisper 모델에 불러온 음성 파일을 적용\n",
    "    # initial_prompt를 통해 우리가 주로 탐색하고자 하는 단어들을 미리 지정\n",
    "    # **decode_options을 통해 언어를 한국어로 고정\n",
    "    result = model.transcribe(file, initial_prompt='들배지기 안다리 밭다리 잡치기 오금당기기 배지기 맞배지기 밀어치기 호미걸이 빗장걸이 덫걸이 차돌리기', \n",
    "                              **decode_options)\n",
    "    \n",
    "    # model의 output은 음성에서 나오는 모든 문장을 하나의 str 형태로 반환하기 때문에 이를 띄어쓰기 기준으로 분할하여 단어별로 리스트 형태로 저장\n",
    "    words = list(result['text'].split(' '))\n",
    "\n",
    "    # model의 output을 result_list에 저장\n",
    "    result_list.append(result['text'])\n",
    "\n",
    "    # 음성에서 나온 씨름의 기술을 저장하기 위한 빈 리스트 생성\n",
    "    appear_list = []\n",
    "\n",
    "    for word in words: # 단어 리스트를 하나씩 불러온다.\n",
    "        # 띄어쓰기를 기준으로 구분하여 아무 것도 존재하지 않는 부분이 생긴다.\n",
    "        # 이를 건너띄게 한다.\n",
    "        if word == '':\n",
    "            continue\n",
    "\n",
    "        # 씨름 기술 단어를 정상적으로 추출하기 위해 단어 뒤에 주로 붙는 것들을 제거\n",
    "        if word[-1] in ['.', '!', ',','을','를','?','는','은']:\n",
    "            word = word[:-1]\n",
    "\n",
    "        # 단어가 씨름 기술 단어 사전에 존재하거나 단어가 다음과 같은 리스트에 존재하는 것으로 끝난다면 모두 기술로 판단하고 리스트에 저장\n",
    "        if word in tech_list or word[-2:] in ['지기','치기','걸이','걸기','리기','다리', '거리']:\n",
    "            appear_list.append(word)\n",
    "\n",
    "    # 만약 기술이 하나도 없다면 0을 반환\n",
    "    if appear_list == []:\n",
    "        tech_df.loc[idx] = [title, 0]\n",
    "        continue\n",
    "\n",
    "    # 중복으로 여러 번 나온 기술을 1개로 합치기 위한 알고리즘\n",
    "    i = 0\n",
    "    while i != (len(appear_list) - 1):\n",
    "        if appear_list[i] == appear_list[i+1]:\n",
    "            del appear_list[i]\n",
    "        else:\n",
    "            i += 1\n",
    "\n",
    "    # 데이터프레임에 title과 기술 사용 횟수를 저장\n",
    "    tech_df.loc[idx] = [title, len(appear_list)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accruacy : 0.8750526810050621\n"
     ]
    }
   ],
   "source": [
    "# 직접 라벨링을 통해 기술 횟수를 기록한 csv 파일을 불러옴\n",
    "score_df = pd.read_csv('../Data/score.csv', encoding='cp949')\n",
    "\n",
    "# model이 생성한 데이터프레임과 위에서 불러온 csv 파일을 merge하여 합침\n",
    "predict_df = pd.merge(score_df, tech_df)\n",
    "\n",
    "# 정확도를 계산하는 함수 생성\n",
    "def get_score(df):\n",
    "    return min(df['tech_count'], (df['score'])) / max(df['tech_count'], (df['score']))\n",
    "\n",
    "# 정확도 계산\n",
    "accuracy = predict_df.apply(get_score, axis=1)\n",
    "\n",
    "print('Accruacy :', np.mean(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whisper.csv에 최종적으로 출력된 데이터프레임을 저장\n",
    "tech_df.to_csv('../Output/whisper.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
